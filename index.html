<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators.">
  <meta name="keywords" content="Text2Video-Zero">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Text2Video-Zero: <br> Text-to-Image Diffusion Models are <br> Zero-Shot Video Generators</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Levon Khachatryan</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="">Andranik Movsisyan</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="">Vahram Tadevosyan</a><sup>1*</sup>,</span>
            </span>
            <span class="author-block">
              <a href="">Roberto Henschel</a><sup>1*</sup>,</span>
            </span><br>
            <span class="author-block">
              <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang">Zhangyang Wang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="">Shant Navasardyan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.humphreyshi.com">Humphrey Shi</a><sup>1,3,4</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Picsart AI Resarch (PAIR),</span>
            <span class="author-block"><sup>2</sup>UT Austin</span>
            <span class="author-block"><sup>3</sup>U of Oregon</span>
            <span class="author-block"><sup>4</sup>UIUC</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2303.13439"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Demo</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/teaser_final.png" style="width:100%;height:600px;">
      <p class="subtitle has-text-centered">
        Our method <span class="dnerf">Text2Video-Zero</span> enables zero-shot video generation using (i) a textual prompt (see rows 1, 2), (ii) a prompt combined with guidance from poses or edges (see lower right), and (iii) Video Instruct-Pix2Pix, i.e., instruction-guided video editing (see lower left). Results are temporally consistent and follow closely the guidance and textual prompts.
      </p>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent text-to-video generation approaches rely on computationally heavy training and require large-scale video datasets. In this paper, we introduce a new task of zero-shot text-to-video generation and propose a low-cost approach (without any training or optimization) by leveraging the power of existing text-to-image synthesis methods (e.g. Stable Diffusion), making them suitable for the video domain. Our key modifications include (i) enriching the latent codes of the generated frames with motion dynamics to keep the global scene and the background time consistent; and (ii) reprogramming frame-level self-attention using a new cross-frame attention of each frame on the first frame, to preserve the context, appearance, and identity of the foreground object. Experiments show that this leads to low overhead, yet high-quality and remarkably consistent video generation. Moreover, our approach is not limited to text-to-video synthesis but is also applicable to other tasks such as conditional and content-specialized video generation, and Video Instruct-Pix2Pix, i.e., instruction-guided video editing. As experiments show, our method performs comparably or sometimes better than recent approaches, despite not being trained on additional video data. Our code will be open sourced at: <a href="https://github.com/Picsart-AI-Research/Text2Video-Zero">https://github.com/Picsart-AI-Research/Text2Video-Zero</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->

    <!-- <video id="teaser" autoplay muted loop playsinline height="100%"> -->
    <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 height="100%">
      <source src="./static/videos/main_video_compressed.mp4"
              type="video/mp4">
    </video>

    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="method" autoplay muted loop playsinline height="100%" src="./static/images/method.png" style="width:100%;height:100%;">
          <p>
            Method overview: Starting from a randomly sampled latent code <span class="math inline">\(x_{T}^{1}\)</span>, we apply <span class="math inline">\(\Delta t\)</span> DDIM backward steps to obtain <span class="math inline">\(x_{T'}^{1}\)</span> using a pre-trained Stable Diffusion model (SD). A specified motion field results for each frame <span class="math inline">\(k\)</span> in a warping function <span class="math inline">\(W_k\)</span> that turns <span class="math inline">\(x_{T'}^{1}\)</span> to <span class="math inline">\(x_{T'}^{k}\)</span>. By enhancing the latent codes with motion dynamics, we determine the global scene and camera motion and achieve temporal consistency in the background and the global scene.
            A subsequent DDPM forward application delivers latent codes <span class="math inline">\(x_{T}^{k}\)</span> for <span class="math inline">\(k=1,\ldots,m\)</span>. By using the (probabilistic) DDPM method, a greater degree of freedom is achieved with respect to the motion of objects.
            Finally, the latent codes are passed to our modified SD model using the proposed cross-frame attention, which uses keys and values from the first frame to generate the image of frame <span class="math inline">\(k=1,\ldots,m\)</span>. By using cross-frame attention,  the appearance and the identity of the foreground object are preserved  throughout the sequence. 
            Optionally, we apply background smoothing. To this end, we employ salient object detection to obtain for each frame <span class="math inline">\(k\) a mask <span class="math inline">\(M^{k}\)</span> indicating the foreground pixels. Finally, for the background (using the mask <span class="math inline">\(M^{k}\)</span>), a convex combination between the latent code <span class="math inline">\(x_{t}^{1}\)</span> of frame one warped to frame <span class="math inline">\(k\)</span> and the latent code <span class="math inline">\(x_{t}^{k}\)</span> is used to further improve the temporal consistency of the background.
          </p>
        </div>
      </div>
    </section>
  </div>
</section>


<section class="section" id="Results">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
    <section class="hero method">
    <div class="container is-max-desktop">
    <div class="hero-body">  
    <h3 class="title">Text-to-Video</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/t2v/cat_running.gif" raw=true></td>
        <td><img src="__assets__/github/results/t2v/playing.gif"></td>
        <td><img src="__assets__/github/results/t2v/running.gif"></td>              
        <td><img src="__assets__/github/results/t2v/skii.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A cat is running on the grass"</td>
        <td width=25% style="text-align:center;">"A panda is playing guitar on times square</td>
        <td width=25% style="text-align:center;">"A man is running in the snow"</td>
        <td width=25% style="text-align:center;">"An astronaut is skiing down the hill"</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/t2v/panda_surfing.gif" raw=true></td>
        <td><img src="__assets__/github/results/t2v/bear_dancing.gif"></td>
        <td><img src="__assets__/github/results/t2v/bicycle.gif"></td>              
        <td><img src="__assets__/github/results/t2v/horse_galloping.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A panda surfing on a wakeboard"</td>
        <td width=25% style="text-align:center;">"A bear dancing on times square</td>
        <td width=25% style="text-align:center;">"A man is riding a bicycle in the sunshine"</td>
        <td width=25% style="text-align:center;">"A horse galloping on a street"</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/t2v/tiger_walking.gif" raw=true></td>
        <td><img src="__assets__/github/results/t2v/panda_surfing_2.gif"></td>
        <td><img src="__assets__/github/results/t2v/horse_galloping_2.gif"></td>              
        <td><img src="__assets__/github/results/t2v/cat_walking.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A tiger walking alone down the street"</td>
        <td width=25% style="text-align:center;">"A panda surfing on a wakeboard</td>
        <td width=25% style="text-align:center;">"A horse galloping on a street"</td>
        <td width=25% style="text-align:center;">"A cute cat running in a beatiful meadow"</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/t2v/horse_galloping_3.gif" raw=true></td>
        <td><img src="__assets__/github/results/t2v/panda_walking.gif"></td>
        <td><img src="__assets__/github/results/t2v/dog_walking.gif"></td>              
        <td><img src="__assets__/github/results/t2v/astronaut.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A horse galloping on a street"</td>
        <td width=25% style="text-align:center;">"A panda walking alone down the street</td>
        <td width=25% style="text-align:center;">"A dog is walking down the street"</td>
        <td width=25% style="text-align:center;">"An astronaut is waving his hands on the moon"</td>
      </tr>
    </table>
    <br>
    <h3 class="title">Text-To-Video with Pose Guidance</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/pose2v/img_bot_left.gif" raw=true><img src="__assets__/github/results/pose2v/pose_bot_left.gif"></td>
        <td><img src="__assets__/github/results/pose2v/img_bot_right.gif" raw=true><img src="__assets__/github/results/pose2v/pose_bot_right.gif"></td>
        <td><img src="__assets__/github/results/pose2v/img_top_left.gif" raw=true><img src="__assets__/github/results/pose2v/pose_top_left.gif"></td>
        <td><img src="__assets__/github/results/pose2v/img_top_right.gif" raw=true><img src="__assets__/github/results/pose2v/pose_top_right.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"A bear dancing on the concrete"</td>
        <td width=25% style="text-align:center;">"An alien dancing under a flying saucer</td>
        <td width=25% style="text-align:center;">"A panda dancing in Antarctica"</td>
        <td width=25% style="text-align:center;">"An astronaut dancing in the outer space"</td>
      </tr>
    </table>
    <br>
    <h3 class="title">Text-To-Video with Edge Guidance</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/edge2v/butterfly.gif" raw=true><img src="__assets__/github/results/edge2v/butterfly_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/head.gif" raw=true><img src="__assets__/github/results/edge2v/head_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/jelly.gif" raw=true><img src="__assets__/github/results/edge2v/jelly_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/mask.gif" raw=true><img src="__assets__/github/results/edge2v/mask_edge.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"White butterfly"</td>
        <td width=25% style="text-align:center;">"Beautiful girl"</td>
          <td width=25% style="text-align:center;">"A jellyfish"</td>
        <td width=25% style="text-align:center;">"beautiful girl halloween style"</td>
      </tr>
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/edge2v/fox.gif" raw=true><img src="__assets__/github/results/edge2v/fix_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/head_2.gif" raw=true><img src="__assets__/github/results/edge2v/head_2_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/santa.gif" raw=true><img src="__assets__/github/results/edge2v/santa_edge.gif"></td>
        <td><img src="__assets__/github/results/edge2v/dear.gif" raw=true><img src="__assets__/github/results/edge2v/dear_edge.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Wild fox is walking"</td>
        <td width=25% style="text-align:center;">"Oil painting of a beautiful girl close-up"</td>
          <td width=25% style="text-align:center;">"A santa claus"</td>
        <td width=25% style="text-align:center;">"A deer"</td>
      </tr>
    </table>
    <br>
    <h3 class="title">Text-To-Video with Edge Guidance and Dreambooth specialization</h3>
    <table class="center">
      <tr><td></td><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="./static/images/canny_db_anime_style.gif" raw=true><img src="./static/images/canny_db_anime_edge.gif"></td>
        <td><img src="./static/images/canny_db_arcane_style.gif" raw=true><img src="./static/images/canny_db_arcane_edge.gif"></td>
        <td><img src="./static/images/canny_db_gta-5_man_style.gif" raw=true><img src="./static/images/canny_db_gta-5_man_edge.gif"></td>
        <td><img src="./static/images/canny_db_img_bot_right.gif" raw=true><img src="./static/images/canny_db_edge_bot_right.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"anime style"</td>
        <td width=25% style="text-align:center;">"arcane style</td>
        <td width=25% style="text-align:center;">"gta-5 man"</td>
        <td width=25% style="text-align:center;">"avatar style"</td>
      </tr>
    </table>
    <br>
    <h3 class="title">Video Instruct Pix2Pix</h3>
    <table class="center">
      <tr><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/up_left.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/bot_left.gif"></td>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/up_mid.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/bot_mid.gif"></td>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/up_right.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_1/bot_right.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Replace man with chimpanze"</td>
        <td width=25% style="text-align:center;">"Make it Van Gogh Starry Night style"</td>
          <td width=25% style="text-align:center;">"Make it Picasso style"</td>
      </tr>
      <tr><td></td><td></td><td></td></tr>
      <tr>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/up_left.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/bot_left.gif"></td>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/up_mid.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/bot_mid.gif"></td>
        <td><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/up_right.gif" raw=true><img src="__assets__/github/results/Video_InstructPix2Pix/frame_2/bot_right.gif"></td>
      </tr>
      <tr>
        <td width=25% style="text-align:center;">"Make it Expressionism style"</td>
        <td width=25% style="text-align:center;">"Make it night"</td>
        <td width=25% style="text-align:center;">"Make it autumn"</td>
      </tr>
    </table>
  </div></div></section>
  </div>
</section>


<section class="section" id='RelatedLinks'>
  <div class="container is-max-desktop content">
    <h2 class="title">Related Links</h2>

    <ul>
      <li><a href="https://ommer-lab.com/research/latent-diffusion-models/"> High-Resolution Image Synthesis with Latent Diffusion Models (a.k.a. LDM & Stable Diffusion)</a></li>
      <li><a href="https://tuneavideo.github.io/"> Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</a></li>
      <li><a href="https://www.timothybrooks.com/instruct-pix2pix/"> InstructPix2Pix: Learning to Follow Image Editing Instructions</a></li>
      <li><a href="https://github.com/lllyasviel/ControlNet"> Adding Conditional Control to Text-to-Image Diffusion Models (a.k.a ControlNet)</a></li>
    </ul>
    <!-- <div class="content has-text-justified">
      <p>
        There's a lot of excellent work that was introduced around the same time as ours.
      </p>
      <p>
        <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
      </p>
      <p>
        <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
        both use deformation fields to model non-rigid scenes.
      </p>
      <p>
        Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
      </p>
      <p>
        There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
      </p>
    </div> -->
  </div></section>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p> If you use our work in your research, please cite our publication: </p>
    <pre><code>@article{text2video-zero,
    title={Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators},
    author={Khachatryan, Levon and Movsisyan, Andranik and Tadevosyan, Vahram and Henschel, Roberto and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
    journal={arXiv preprint arXiv:2303.13439},
    year={2023}}
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link" href="./static/videos/nerfies_paper.pdf"> -->
      <a class="icon-link" href="https://arxiv.org/pdf/2303.13439.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled> -->
      <a class="icon-link" href="https://github.com/Picsart-AI-Research/Text2Video-Zero" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
